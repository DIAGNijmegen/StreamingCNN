{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:28.905253Z",
     "start_time": "2018-04-18T08:29:28.885914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:29.007994Z",
     "start_time": "2018-04-18T08:29:28.991690Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from ssgd import StreamingSGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A StreamingSGD compatible model now needs to be able to \"detach\" layers as well as gather input/output and gradients. It also needs a list of layers. See below for implementation example. In the future we want to implement this using PyTorch hooks and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:38.673734Z",
     "start_time": "2018-04-18T08:29:38.524919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExampleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleNet, self).__init__()\n",
    "        \n",
    "        self.input_layer = torch.nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        self.layers = [self.input_layer]\n",
    "\n",
    "        for i in range(6):  # use 9 for 8194 x 8194 images\n",
    "            self.add_block(i)\n",
    "        \n",
    "        final_conv5 = torch.nn.Conv2d(3, 1, kernel_size=8)\n",
    "        self.add_module(\"final\", final_conv5)\n",
    "        \n",
    "        self.layers.extend([final_conv5])\n",
    "        \n",
    "    def add_block(self, i):\n",
    "        conv1 = torch.nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        conv2 = torch.nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        conv3 = torch.nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "        maxpool = torch.nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.add_module(\"conv1-\" + str(i), conv1)\n",
    "        self.add_module(\"conv2-\" + str(i), conv2)\n",
    "        self.add_module(\"conv3-\" + str(i), conv3)\n",
    "        self.add_module(\"maxpool-\" + str(i), maxpool)\n",
    "\n",
    "        self.layers.extend([conv1, conv2, conv3, maxpool])\n",
    "        \n",
    "    def backward(self, gradient):\n",
    "        self.gradients = []\n",
    "        for i, output in reversed(list(enumerate(self.output))):\n",
    "            if i < (len(self.output) - 1):\n",
    "                gradient = self.input[i+1].grad\n",
    "            output.backward(gradient=gradient, retain_graph=True)\n",
    "            self.gradients.append(gradient)\n",
    "\n",
    "    def forward(self, x, stop_index=-1, start_index=0, detach=False):\n",
    "        if detach:\n",
    "            self.output = []\n",
    "            self.input = []\n",
    "        for i, layer in enumerate(self.layers[start_index:]):\n",
    "            if detach:\n",
    "                x = torch.autograd.Variable(x.data, requires_grad=detach)\n",
    "                self.input.append(x)\n",
    "            if i == stop_index:\n",
    "                break\n",
    "            if i + 1 == len(self.layers[start_index:]):\n",
    "                x = layer(x)\n",
    "                x = x.view(-1, 1)\n",
    "                x = F.sigmoid(x)\n",
    "            else:\n",
    "                x = F.relu(layer(x))\n",
    "            if detach:\n",
    "                self.output.append(x)\n",
    "        return x\n",
    "\n",
    "model = ExampleNet()\n",
    "# model = model.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight initialization; we use positive values to generate large gradients, better for testing if final gradients are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:38.921388Z",
     "start_time": "2018-04-18T08:29:38.899959Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.weight.data.fill_(0.04)\n",
    "        layer.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:39.075343Z",
     "start_time": "2018-04-18T08:29:39.054152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleNet(\n",
      "  (input_layer): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1-0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2-0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3-0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool-0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv1-1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2-1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3-1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool-1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv1-2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2-2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3-2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool-2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv1-3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2-3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3-3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool-3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv1-4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2-4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3-4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool-4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv1-5): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2-5): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3-5): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool-5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (final): Conv2d(3, 1, kernel_size=(8, 8), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:39.241369Z",
     "start_time": "2018-04-18T08:29:39.220529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sCNN = StreamingSGD(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:39.577299Z",
     "start_time": "2018-04-18T08:29:39.551198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_index = 13  # use 21 for 8194x8194 images\n",
    "img_size = 514  # try 8194, see last segment for details\n",
    "\n",
    "cuda = False  # execute this notebook on the GPU\n",
    "verbose = True  # enable / disable logging\n",
    "divide_in = 2  # tip: use 25 for 8194x8194 when memory constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure streaming SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:39.899404Z",
     "start_time": "2018-04-18T08:29:39.875077Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:40.093640Z",
     "start_time": "2018-04-18T08:29:40.062245Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating patch boxes...\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 257.0, 257.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 3, 257.0, 257.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 257.0, 257.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 257.0, 257.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 128.0, 128.0] [2.0, 2.0] [0.0, 1.0, 0.0, 1.0] MaxPool2d\n",
      "[1, 3, 128.0, 128.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 128.0, 128.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 128.0, 128.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 64.0, 64.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "Embedding divided in tile sizes: (32, 32) \n",
      "\n",
      "[1, 3, 346.0, 346.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 346.0, 346.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 346.0, 346.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 346.0, 346.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 173.0, 173.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 3, 173.0, 173.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 173.0, 173.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 173.0, 173.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 86.0, 86.0] [2.0, 2.0] [0.0, 1.0, 0.0, 1.0] MaxPool2d\n",
      "[1, 3, 86.0, 86.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 86.0, 86.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 86.0, 86.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 43.0, 43.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "Patch size forward: (302, 302) \n",
      "\n",
      "Calculating gradient. Embedding size: (58.0, 58.0)\n",
      "Done. \n",
      "Backward patch size (for forward pass): (346, 346)\n"
     ]
    }
   ],
   "source": [
    "sCNN.configure(model.layers, stop_index, (img_size, img_size, 3), 2, cuda, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:40.477559Z",
     "start_time": "2018-04-18T08:29:40.449079Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 514.0, 514.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 257.0, 257.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 3, 257.0, 257.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 257.0, 257.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 257.0, 257.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 128.0, 128.0] [2.0, 2.0] [0.0, 1.0, 0.0, 1.0] MaxPool2d\n",
      "[1, 3, 128.0, 128.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 128.0, 128.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 128.0, 128.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 64.0, 64.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 3, 64.0, 64.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 64.0, 64.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 64.0, 64.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 32.0, 32.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 3, 32.0, 32.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 32.0, 32.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 32.0, 32.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 16.0, 16.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 3, 16.0, 16.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 16.0, 16.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 16.0, 16.0] [1.0, 1.0] [1.0, 1.0, 1.0, 1.0] Conv2d\n",
      "[1, 3, 8.0, 8.0] [2.0, 2.0] [0.0, 0.0, 0.0, 0.0] MaxPool2d\n",
      "[1, 1, 1.0, 1.0] [1.0, 1.0] [3.0, 4.0, 3.0, 4.0] Conv2d\n"
     ]
    }
   ],
   "source": [
    "sCNN._getreconstructioninformation(model.layers, (1, img_size, img_size, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random image and fake label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current implementation the whole image needs to be able to fit in memory (RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:30:15.521613Z",
     "start_time": "2018-04-18T08:30:15.454673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(3, img_size, img_size).normal_(0, 1)\n",
    "target = torch.FloatTensor(1, 1).fill_(0)\n",
    "\n",
    "# image = image.double()\n",
    "# target = target.double()\n",
    "\n",
    "if cuda:\n",
    "    target = target.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:30:15.651297Z",
     "start_time": "2018-04-18T08:30:15.632261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_var = torch.autograd.Variable(image)\n",
    "# image_var = image_var.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:30:15.858857Z",
     "start_time": "2018-04-18T08:30:15.838522Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:30:16.151982Z",
     "start_time": "2018-04-18T08:30:16.054075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 55.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing forward pass...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output, feature_map = sCNN.forward(image_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:30:16.397751Z",
     "start_time": "2018-04-18T08:30:16.359948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96404803]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.071954Z",
     "start_time": "2018-04-18T08:29:14.996133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/anaconda/lib/python3.6/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([81, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (1) != input nelement (81)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d2d6b287b072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         return F.binary_cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 430\u001b[0;31m                                       size_average=self.size_average)\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 1192\u001b[0;31m                          \"!= input nelement ({})\".format(target.nelement(), input.nelement()))\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (1) != input nelement (81)"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, torch.autograd.Variable(target)); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:30:22.174989Z",
     "start_time": "2018-04-18T08:30:22.161977Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cc85a0395563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "full_gradients = sCNN.backward(image_var, feature_map, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Everything filled\" means that all gradients were reconstructed succesfully!\n",
    "\n",
    "Save the gradients of the conv2d layer to compare with normal SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.073760Z",
     "start_time": "2018-04-18T08:29:14.323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streaming_conv_gradients = []\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            streaming_conv_gradients.append(layer.weight.grad.clone()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to normal SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the gradients and perform a normal for backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.074715Z",
     "start_time": "2018-04-18T08:29:14.326Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            layer.weight.grad.data.zero_()\n",
    "            layer.bias.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.075811Z",
     "start_time": "2018-04-18T08:29:14.327Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model.forward(image_var[None], detach=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.077057Z",
     "start_time": "2018-04-18T08:29:14.328Z"
    }
   },
   "outputs": [],
   "source": [
    "output.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output should be the same as the streaming SGD output, if so the loss will also be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.078371Z",
     "start_time": "2018-04-18T08:29:14.331Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = criterion(output, torch.autograd.Variable(target)); loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a normal PyTorch backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.079153Z",
     "start_time": "2018-04-18T08:29:14.332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the gradients of the conv2d layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.080305Z",
     "start_time": "2018-04-18T08:29:14.335Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_conv_gradients = []\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            normal_conv_gradients.append(layer.weight.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.081151Z",
     "start_time": "2018-04-18T08:29:14.336Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(streaming_conv_gradients)):\n",
    "    max_diff = torch.max(torch.abs(streaming_conv_gradients[i].data - \n",
    "                      normal_conv_gradients[i].data))\n",
    "    print(\"Layer\", i, \"\\taverage gradient size:\", torch.mean(streaming_conv_gradients[i].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:29:15.081803Z",
     "start_time": "2018-04-18T08:29:14.338Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(streaming_conv_gradients)):\n",
    "    max_diff = torch.max(torch.abs(streaming_conv_gradients[i].data - \n",
    "                      normal_conv_gradients[i].data))\n",
    "    print(\"Layer\", i, \"\\tmax difference between gradients:\", max_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the difference of the gradients of the conv2d layers between the methods is (almost) numerically equivalent. The small differences are because of loss of significance with the floating points calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Things to try:\n",
    "\n",
    "* Use doubles instead of floats to reduce the difference (use model.double() and image_var.double())\n",
    "* Make the image bigger than would fit on a GPU \n",
    "    - e.g. 8194x8194, make sure to add 3 more blocks in the model (see comments)\n",
    "* If you want you can compare the reconstructed input gradients of each layer: \n",
    "    - pass fill_gradient=True in backward() function\n",
    "    - compare full_gradients with self.model.gradients after the full model backward pass.\n",
    "* For testing purposes the number of filters is small in this notebook, try increasing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "154px",
    "left": "2276.98px",
    "top": "94.9219px",
    "width": "413px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
