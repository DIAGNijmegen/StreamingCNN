{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:46.383407Z",
     "start_time": "2019-11-06T13:05:45.654321Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ssgd import StreamingCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:46.387840Z",
     "start_time": "2019-11-06T13:05:46.385298Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:46.399120Z",
     "start_time": "2019-11-06T13:05:46.389968Z"
    }
   },
   "outputs": [],
   "source": [
    "padding = 0\n",
    "\n",
    "stream_net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:46.405822Z",
     "start_time": "2019-11-06T13:05:46.400963Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.weight.data *= 2.5\n",
    "        layer.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:46.410012Z",
     "start_time": "2019-11-06T13:05:46.407177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): ReLU()\n",
      "  (7): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (8): ReLU()\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (11): ReLU()\n",
      "  (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (13): ReLU()\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(stream_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:46.415172Z",
     "start_time": "2019-11-06T13:05:46.411427Z"
    }
   },
   "outputs": [],
   "source": [
    "tile_size = 512\n",
    "img_size = 1024\n",
    "cuda = True  # execute this notebook on the GPU\n",
    "verbose = True   # enable / disable logging\n",
    "dtype = torch.double  # test with double precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure streaming SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:48.307126Z",
     "start_time": "2019-11-06T13:05:46.417134Z"
    }
   },
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    stream_net.cuda()\n",
    "    stream_net.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.074359Z",
     "start_time": "2019-11-06T13:05:48.309256Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Output lost (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      "\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " (Lost top:0.0 left:0.0 bottom:0.0 right:0.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:0.0 left:0.0 bottom:1.0 right:1.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:2.0 left:2.0 bottom:3.0 right:3.0)\n",
      "\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " (Lost top:4.0 left:4.0 bottom:5.0 right:5.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:8.0 left:8.0 bottom:10.0 right:10.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:10.0 left:10.0 bottom:12.0 right:12.0)\n",
      "\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " (Lost top:12.0 left:12.0 bottom:14.0 right:14.0)\n",
      "\n",
      " Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:24.0 left:24.0 bottom:28.0 right:28.0)\n",
      "\n",
      " Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " (Lost top:26.0 left:26.0 bottom:30.0 right:30.0)\n",
      "\n",
      " Input gradient lost (Lost top:28.0 left:28.0 bottom:32.0 right:32.0)\n"
     ]
    }
   ],
   "source": [
    "sCNN = StreamingCNN(stream_net, tile_shape=(1, 3, tile_size, tile_size), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Generate random image and fake label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current implementation the whole image needs to be able to fit in memory (RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.118343Z",
     "start_time": "2019-11-06T13:05:49.076723Z"
    }
   },
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(3, img_size, img_size).normal_(0, 1)\n",
    "target = torch.tensor(50.)  # big value so we get larger gradients\n",
    "\n",
    "image = image.type(dtype)\n",
    "target = target.type(dtype)\n",
    "\n",
    "if cuda:\n",
    "    target = target.cuda()\n",
    "    image = image.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.123607Z",
     "start_time": "2019-11-06T13:05:49.119959Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run through network using streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.821198Z",
     "start_time": "2019-11-06T13:05:49.125056Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 124, 124])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_output = sCNN.forward(image[None]); stream_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.824694Z",
     "start_time": "2019-11-06T13:05:49.822525Z"
    }
   },
   "outputs": [],
   "source": [
    "stream_output.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.830933Z",
     "start_time": "2019-11-06T13:05:49.826060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8080944048, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sigmoid(torch.mean(stream_output)); output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.836661Z",
     "start_time": "2019-11-06T13:05:49.832414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-70.2330147828, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, target); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:05:49.840306Z",
     "start_time": "2019-11-06T13:05:49.838062Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.487536Z",
     "start_time": "2019-11-06T13:05:49.841606Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles in backprop: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:11<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "full_gradients = sCNN.backward(image[None], stream_output.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.491301Z",
     "start_time": "2019-11-06T13:06:01.488929Z"
    }
   },
   "outputs": [],
   "source": [
    "sCNN.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Everything reconstructed\" means that all gradients were reconstructed succesfully!\n",
    "\n",
    "Save the gradients of the conv2d layer to compare with normal SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.496831Z",
     "start_time": "2019-11-06T13:06:01.492847Z"
    }
   },
   "outputs": [],
   "source": [
    "streaming_conv_gradients = []\n",
    "\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            streaming_conv_gradients.append(layer.weight.grad.clone()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to normal SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the gradients and perform a normal for backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.505952Z",
     "start_time": "2019-11-06T13:06:01.500201Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            layer.weight.grad.data.zero_()\n",
    "            layer.bias.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output should be the same as the streaming SGD output, if so the loss will also be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.520669Z",
     "start_time": "2019-11-06T13:06:01.508042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conventional_output = stream_net(image[None]); conventional_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.818604Z",
     "start_time": "2019-11-06T13:06:01.522569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal output to streaming\n"
     ]
    }
   ],
   "source": [
    "# NOTE: sometimes output can be slightly bigger (if tiles do not fit nicely on input image)\n",
    "max_error = torch.abs(stream_output - conventional_output).max().item()\n",
    "\n",
    "if max_error < 1e-7:\n",
    "    print(\"Equal output to streaming\")\n",
    "else:\n",
    "    print(\"NOT equal output to streaming\"),\n",
    "    print(\"error:\", max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.828395Z",
     "start_time": "2019-11-06T13:06:01.822649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8080944048, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sigmoid(torch.mean(conventional_output)); output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.840589Z",
     "start_time": "2019-11-06T13:06:01.832608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-70.2330147828, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, target); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.850219Z",
     "start_time": "2019-11-06T13:06:01.842832Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the gradients of the conv2d layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the gradients of the conv2d layer to compare with normal SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:01.857810Z",
     "start_time": "2019-11-06T13:06:01.851536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 0 \t Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 1 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 2 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 3 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 4 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 5 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "normal_conv_gradients = []\n",
    "j = 0\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            normal_conv_gradients.append(layer.weight.grad) \n",
    "            print('Conv layer', j, '\\t', layer)\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:03.744645Z",
     "start_time": "2019-11-06T13:06:01.860077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional \n",
      "\n",
      "Conv layer 0 \t average gradient size: 0.6633402018338846\n",
      "Conv layer 1 \t average gradient size: 1.6737470297611399\n",
      "Conv layer 2 \t average gradient size: 2.774223800907205\n",
      "Conv layer 3 \t average gradient size: 2.8184983626562485\n",
      "Conv layer 4 \t average gradient size: 2.4635763198365033\n",
      "Conv layer 5 \t average gradient size: 2.2630631082562744\n"
     ]
    }
   ],
   "source": [
    "print('Conventional', '\\n')\n",
    "\n",
    "for i in range(len(streaming_conv_gradients)):\n",
    "    print(\"Conv layer\", i, \"\\t average gradient size:\", \n",
    "          float(torch.mean(torch.abs(streaming_conv_gradients[i].data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:03.752311Z",
     "start_time": "2019-11-06T13:06:03.746000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming \n",
      "\n",
      "Conv layer 0 \t average gradient size: 0.6633402018338848\n",
      "Conv layer 1 \t average gradient size: 1.6737470297611394\n",
      "Conv layer 2 \t average gradient size: 2.7742238009072038\n",
      "Conv layer 3 \t average gradient size: 2.818498362656249\n",
      "Conv layer 4 \t average gradient size: 2.463576319836503\n",
      "Conv layer 5 \t average gradient size: 2.2630631082562727\n"
     ]
    }
   ],
   "source": [
    "print('Streaming', '\\n')\n",
    "for i in range(len(normal_conv_gradients)):\n",
    "    print(\"Conv layer\", i, \"\\t average gradient size:\", \n",
    "          float(torch.mean(torch.abs(normal_conv_gradients[i].data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:06:03.761291Z",
     "start_time": "2019-11-06T13:06:03.754508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 0 \tmax difference between kernel gradients: 7.37188088351104e-14\n",
      "Conv layer 1 \tmax difference between kernel gradients: 1.8385293287792592e-13\n",
      "Conv layer 2 \tmax difference between kernel gradients: 6.821210263296962e-13\n",
      "Conv layer 3 \tmax difference between kernel gradients: 3.410605131648481e-13\n",
      "Conv layer 4 \tmax difference between kernel gradients: 3.801403636316536e-13\n",
      "Conv layer 5 \tmax difference between kernel gradients: 7.460698725481052e-14\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(streaming_conv_gradients)):\n",
    "    diff = torch.abs(streaming_conv_gradients[i].data - normal_conv_gradients[i].data)\n",
    "    max_diff = diff.max()\n",
    "    print(\"Conv layer\", i, \"\\tmax difference between kernel gradients:\", float(max_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the difference of the gradients of the conv2d layers between the methods is (almost) numerically equivalent. The small differences are because of loss of significance with the floating points calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Things to try:\n",
    "\n",
    "* Use doubles instead of floats to reduce the difference (use model.double() and image_var.double())\n",
    "* Make the image bigger than would fit on a GPU \n",
    "    - e.g. 8194x8194, make sure to add 3 more blocks in the model (see comments)\n",
    "* If you want you can compare the reconstructed input gradients of each layer: \n",
    "    - pass fill_gradient=True in backward() function\n",
    "    - compare full_gradients with self.model.gradients after the full model backward pass.\n",
    "* For testing purposes the number of filters is small in this notebook, try increasing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "344px",
    "left": "2614.95px",
    "top": "98.0799px",
    "width": "383px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
